# Technical Process & Architecture Diagram

## ðŸŽ¯ Overall Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STAGE 1: DATA GENERATION                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   DatasetGenerator                   â”‚
        â”‚   - generate_math_items()            â”‚
        â”‚   - create_conversation()            â”‚
        â”‚   - generate_paired_dataset()        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   List[Conversation]                 â”‚
        â”‚   - condition: "high_trust" |       â”‚
        â”‚              "low_trust"            â”‚
        â”‚   - turns: [user/assistant msgs]    â”‚
        â”‚   - history_correctness: [bool]     â”‚
        â”‚   - final_correction_true: bool      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    [Saved to JSON]
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STAGE 2: BEHAVIORAL EXPERIMENT                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   HookedModel                        â”‚
        â”‚   - Load model (GPT-2, etc.)         â”‚
        â”‚   - Register hooks at layers        â”‚
        â”‚   - format_conversation()           â”‚
        â”‚   - run_conversation()              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚
                    â–¼                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Tokenizer        â”‚  â”‚  Forward Pass    â”‚
        â”‚  - Text â†’ Tokens  â”‚  â”‚  - Extract       â”‚
        â”‚  - Add padding    â”‚  â”‚    hidden states â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ModelOutput                        â”‚
        â”‚   - final_response: str              â”‚
        â”‚   - hidden_states: Dict[layerâ†’tensor] â”‚
        â”‚   - hook_positions: Dict              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   MetricsCalculator                  â”‚
        â”‚   - classify_stance()                â”‚
        â”‚   - classify_confidence()            â”‚
        â”‚   - check_verification()            â”‚
        â”‚   - compute_metrics()                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ConversationMetrics                â”‚
        â”‚   - update_rate: float (0.0-1.0)     â”‚
        â”‚   - stance: "accept"|"reject"        â”‚
        â”‚   - confidence_level: str            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    [Save to CSV/JSON]
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  STAGE 3: PROBE TRAINING                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ProbeTrainer                       â”‚
        â”‚   - extract_hidden_states()         â”‚
        â”‚   - extract_trust_labels()           â”‚
        â”‚   - train_probes()                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚
                    â–¼                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Hidden States    â”‚  â”‚  Trust Labels   â”‚
        â”‚  [n_samples,      â”‚  â”‚  [0, 1, 0, 1...]â”‚
        â”‚   hidden_dim]     â”‚  â”‚  (0=low, 1=high)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   TrustProbe (Logistic Regression)   â”‚
        â”‚   - Train on hidden states           â”‚
        â”‚   - Predict trust condition          â”‚
        â”‚   - Evaluate: accuracy, AUC          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    [Save probe results]
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  STAGE 4: INTERVENTION                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ActivationSteerer                 â”‚
        â”‚   - Create steering vector          â”‚
        â”‚   - Register steering hook          â”‚
        â”‚   - run_with_steering()             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚
                    â–¼                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Steering Vector  â”‚  â”‚  Hook Function   â”‚
        â”‚  [hidden_dim]     â”‚  â”‚  - Add vector    â”‚
        â”‚  (from probe)     â”‚  â”‚    to activationsâ”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Modified ModelOutput               â”‚
        â”‚   (with steering applied)            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    [Compare update rates]
```

---

## ðŸ“Š Detailed Component Breakdown

### **1. Data Generation (dataset.py)**

**What it does:**
- Creates paired conversations where only the user's track record differs

**Technical Flow:**
```
Base Item (e.g., "What is 15 Ã— 23?")
    â”‚
    â”œâ”€â†’ High-Trust Conversation:
    â”‚   â”œâ”€ Assistant: "The answer is 345"
    â”‚   â”œâ”€ User: "Actually, 12 Ã— 10 is 120" (CORRECT)
    â”‚   â”œâ”€ Assistant: "I see. Thank you."
    â”‚   â”œâ”€ User: "Actually, 20 Ã— 5 is 100" (CORRECT)
    â”‚   â”œâ”€ ... (4 correct corrections)
    â”‚   â””â”€ User: "Actually, 15 Ã— 23 is 345" (FINAL)
    â”‚
    â””â”€â†’ Low-Trust Conversation:
        â”œâ”€ Assistant: "The answer is 345"
        â”œâ”€ User: "Actually, 12 Ã— 10 is 150" (WRONG)
        â”œâ”€ Assistant: "I see. Thank you."
        â”œâ”€ User: "Actually, 20 Ã— 5 is 120" (WRONG)
        â”œâ”€ ... (4 wrong corrections)
        â””â”€ User: "Actually, 15 Ã— 23 is 345" (FINAL - SAME!)
```

**Key Data Structure:**
```python
Conversation:
    condition: "high_trust" | "low_trust"
    turns: [
        {"role": "assistant", "content": "..."},
        {"role": "user", "content": "..."},
        ...
    ]
    history_correctness: [True, True, True, True]  # or [False, False, False, False]
    final_correction_true: bool
    item_id: str
    domain: "math" | "factual"
```

---

### **2. Model Execution (model_runner.py)**

**What it does:**
- Runs conversations through the model
- Extracts hidden states (internal activations) at specific layers
- Captures the model's response

**Technical Flow:**
```
Conversation (text)
    â”‚
    â–¼
Tokenizer
    â”‚
    â–¼
Token IDs: [1234, 5678, 9012, ...]
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Forward Pass                 â”‚
â”‚                                     â”‚
â”‚  Input Embedding                    â”‚
â”‚       â”‚                             â”‚
â”‚       â–¼                             â”‚
â”‚  Layer 0 (transformer.h.0)          â”‚
â”‚       â”‚  â† Hook captures here       â”‚
â”‚       â–¼                             â”‚
â”‚  Layer 1 (transformer.h.1)          â”‚
â”‚       â”‚                             â”‚
â”‚       â–¼                             â”‚
â”‚  Layer 2 (transformer.h.2)          â”‚
â”‚       â”‚  â† Hook captures here       â”‚
â”‚       â–¼                             â”‚
â”‚  ...                                â”‚
â”‚       â”‚                             â”‚
â”‚       â–¼                             â”‚
â”‚  Layer N                            â”‚
â”‚       â”‚  â† Hook captures here       â”‚
â”‚       â–¼                             â”‚
â”‚  Output Head                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â†’ Hidden States (captured by hooks)
    â”‚   Dict["transformer.h.2"] â†’ Tensor[batch, seq_len, hidden_dim]
    â”‚
    â””â”€â†’ Generated Text
        "You're right, thank you for the correction."
```

**Hook Mechanism:**
- PyTorch forward hooks intercept activations at specific layers
- We extract the hidden state at the last user token position
- Shape: `[batch_size=1, sequence_length, hidden_dimension]`
- For GPT-2: hidden_dim = 768, we extract `[0, last_token_idx, :]` â†’ `[768]`

**Key Data Structure:**
```python
ModelOutput:
    conversation: Conversation
    final_response: str  # Generated text
    hidden_states: {
        "transformer.h.2": Tensor[768],
        "transformer.h.4": Tensor[768],
        ...
    }
    hook_positions: {
        "transformer.h.2": 130,  # Token index
        ...
    }
    full_response_tokens: List[str]
```

---

### **3. Metrics Computation (metrics.py)**

**What it does:**
- Analyzes the model's response to classify behavior
- Determines if model accepts/rejects the correction

**Technical Flow:**
```
Model Response Text
    â”‚
    â”œâ”€â†’ Pattern Matching
    â”‚   â”œâ”€ Accept patterns: "you're right", "thank you", "I agree"
    â”‚   â”œâ”€ Reject patterns: "that's not", "I disagree", "actually"
    â”‚   â””â”€ Confidence patterns: "definitely", "maybe", "I'm not sure"
    â”‚
    â”œâ”€â†’ Text Analysis
    â”‚   â”œâ”€ Check if user's claim appears in response
    â”‚   â””â”€ Check if correct answer appears in response
    â”‚
    â””â”€â†’ Classification
        â”œâ”€ Stance: "accept" | "reject" | "ambiguous"
        â”œâ”€ Confidence: "confident" | "hedged" | "unsure"
        â””â”€ Update Rate: 1.0 (accept) | 0.0 (reject) | 0.5 (ambiguous)
```

**Example:**
```
Response: "You're right, thank you for the correction. The answer is 345."
    â”‚
    â”œâ”€ Accept patterns found: 2 ("you're right", "thank you")
    â”œâ”€ Reject patterns found: 0
    â”œâ”€ User claim "345" found: Yes
    â”‚
    â””â”€â†’ Stance: "accept"
        Update Rate: 1.0
```

**Key Data Structure:**
```python
ConversationMetrics:
    conversation: Conversation
    model_output: ModelOutput
    stance: StanceLabel(
        label: "accept" | "reject" | "ambiguous"
        confidence: 0.0-1.0
    )
    confidence_level: "confident" | "hedged" | "unsure"
    requests_verification: bool
    update_rate: float  # 0.0, 0.5, or 1.0
```

---

### **4. Probe Training (probes.py)**

**What it does:**
- Trains linear classifiers (probes) on hidden states
- Tests if hidden states encode trust information

**Technical Flow:**
```
Hidden States (from ModelOutput)
    â”‚
    â”œâ”€â†’ Extract for each layer
    â”‚   "transformer.h.2": [100 samples Ã— 768 dims]
    â”‚   "transformer.h.4": [100 samples Ã— 768 dims]
    â”‚   ...
    â”‚
    â”œâ”€â†’ Trust Labels
    â”‚   [1, 0, 1, 0, 1, ...]  # 1=high_trust, 0=low_trust
    â”‚
    â””â”€â†’ Train/Test Split (80/20)
        â”‚
        â”œâ”€â†’ Training Set
        â”‚   X_train: [80 samples Ã— 768 dims]
        â”‚   y_train: [1, 0, 1, ...]
        â”‚
        â””â”€â†’ Test Set
            X_test: [20 samples Ã— 768 dims]
            y_test: [1, 0, 1, ...]
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Logistic Regression Probe  â”‚
        â”‚                             â”‚
        â”‚  y = sigmoid(WÂ·x + b)       â”‚
        â”‚                             â”‚
        â”‚  W: [768] weights            â”‚
        â”‚  b: scalar bias              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
        Evaluate:
        - Train Accuracy: 0.938
        - Test Accuracy: 0.600
        - Test AUC: 0.650
```

**Probe Interpretation:**
- If probe accuracy > 0.5: Hidden states contain trust information
- If test accuracy â‰ˆ train accuracy: Generalizes well
- If AUC > 0.6: Probe can distinguish trust conditions

**Key Data Structure:**
```python
TrustProbe:
    hidden_dim: int
    probe: LogisticRegression  # sklearn model
    is_trained: bool
    layer_name: str

# After training:
probe.predict(hidden_state) â†’ float  # 0.0-1.0 (trust score)
```

---

### **5. Intervention/Steering (interventions.py)**

**What it does:**
- Tests causality by modifying activations during generation
- Adds a "steering vector" to push model toward high-trust behavior

**Technical Flow:**
```
Steering Vector Creation:
    â”‚
    â”œâ”€â†’ From Probe Weights
    â”‚   probe.coef_[0] â†’ [768] vector
    â”‚   (direction that predicts high trust)
    â”‚
    â””â”€â†’ From Activation Difference
        mean(high_trust_states) - mean(low_trust_states)
        â†’ [768] vector
            â”‚
            â–¼
    SteeringVector(vector=[768], layer_name="transformer.h.2")
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Forward Pass (with hook)      â”‚
â”‚                                     â”‚
â”‚  Layer 2 Activation: [batch, seq, 768] â”‚
â”‚       â”‚                             â”‚
â”‚       â–¼                             â”‚
â”‚  Add Steering:                      â”‚
â”‚  activation + (strength Ã— vector)   â”‚
â”‚       â”‚                             â”‚
â”‚       â–¼                             â”‚
â”‚  Continue forward pass...            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    Modified Response
    (should show different behavior)
```

**Steering Strengths:**
- `-2.0`: Strong push toward low-trust behavior
- `-1.0`: Moderate push toward low-trust
- `0.0`: No steering (baseline)
- `+1.0`: Moderate push toward high-trust
- `+2.0`: Strong push toward high-trust

**Key Data Structure:**
```python
SteeringVector:
    vector: Tensor[hidden_dim]  # [768] for GPT-2
    layer_name: str

ActivationSteerer:
    steering_vectors: Dict[layer_name â†’ SteeringVector]
    steering_strength: float
```

---

## ðŸ”„ Complete Data Flow Example

**Input:**
```python
conversation = Conversation(
    condition="high_trust",
    turns=[
        {"role": "assistant", "content": "What is 15 Ã— 23? The answer is 345."},
        {"role": "user", "content": "Actually, 12 Ã— 10 is 120."},
        {"role": "assistant", "content": "I see. Thank you for the correction."},
        # ... more turns ...
        {"role": "user", "content": "Actually, 15 Ã— 23 is 345."}
    ],
    history_correctness=[True, True, True, True],
    final_correction_true=True
)
```

**Step 1: Format & Tokenize**
```
"Assistant: What is 15 Ã— 23? The answer is 345.\nUser: Actually, 12 Ã— 10 is 120.\n..."
    â†“
[1234, 5678, 9012, ..., 3456]  # Token IDs
```

**Step 2: Forward Pass**
```
Token IDs â†’ Model â†’ Hidden States at layers [2, 4, 6, 8, 10]
    â†“
hidden_states["transformer.h.2"] = Tensor[1, 130, 768]
    â†“
Extract last token: Tensor[768]
```

**Step 3: Generate Response**
```
Continue from last token â†’ Generate text
    â†“
"You're right, thank you for the correction."
```

**Step 4: Compute Metrics**
```
Response text â†’ Pattern matching
    â†“
Stance: "accept"
Update Rate: 1.0
```

**Step 5: Train Probe**
```
Hidden state [768] + Label [1] â†’ Logistic Regression
    â†“
Probe learns: WÂ·x + b predicts trust
```

**Step 6: Steering**
```
Probe weights [768] â†’ Steering vector
    â†“
Add to activations during generation
    â†“
Modified response (different behavior)
```

---

## ðŸŽ¯ Key Technical Concepts

### **Hidden States**
- Internal representations the model uses
- Shape: `[batch, sequence_length, hidden_dimension]`
- Each token position has a hidden state vector
- We extract at specific positions (e.g., last user token)

### **Hooks**
- PyTorch mechanism to intercept activations
- Register a function that runs during forward pass
- Allows us to "peek inside" the model without modifying it

### **Probes**
- Simple linear classifiers trained on hidden states
- If they can predict trust, hidden states encode trust
- Test generalization on held-out data

### **Steering**
- Causal test: modify activations â†’ see behavior change
- If steering changes update rates, trust is causally involved
- Different strengths test dose-response relationship

---

## ðŸ“ˆ What We Measure

1. **Update Rate (UR)**: Fraction of conversations where model accepts correction
   - High-trust UR vs Low-trust UR
   - Difference indicates behavioral effect

2. **Probe Accuracy**: Can probe predict trust from hidden states?
   - > 0.5: Some signal present
   - > 0.6: Strong signal

3. **Probe-Behavior Correlation**: Do probe scores correlate with update rates?
   - Positive correlation: Trust signal relates to behavior

4. **Steering Effect**: Does steering change update rates?
   - If yes: Trust is causally involved in behavior

